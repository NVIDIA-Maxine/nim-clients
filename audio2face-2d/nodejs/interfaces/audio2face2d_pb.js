// source: audio2face2d.proto
/**
 * @fileoverview
 * @enhanceable
 * @suppress {missingRequire} reports error on implicit type usages.
 * @suppress {messageConventions} JS Compiler reports an error if a variable or
 *     field starts with 'MSG_' and isn't a translatable message.
 * @public
 */
// GENERATED CODE -- DO NOT EDIT!
/* eslint-disable */
// @ts-nocheck

var jspb = require('google-protobuf');
var goog = jspb;
var global = (function() {
  if (this) { return this; }
  if (typeof window !== 'undefined') { return window; }
  if (typeof global !== 'undefined') { return global; }
  if (typeof self !== 'undefined') { return self; }
  return Function('return this')();
}.call(null));

var google_protobuf_empty_pb = require('google-protobuf/google/protobuf/empty_pb.js');
goog.object.extend(proto, google_protobuf_empty_pb);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.AnimateConfig', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.AnimateRequest', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.StreamInputCase', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.AnimateResponse', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.StreamOutputCase', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.AnimationCroppingMode', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.HeadPoseMode', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.ModelSelection', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.Quaternion', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.QuaternionStream', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.Vector3f', null, global);
goog.exportSymbol('proto.nvidia.maxine.audio2face2d.v1.Vector3fStream', null, global);
/**
 * Generated by JsPbCodeGenerator.
 * @param {Array=} opt_data Optional initial data array, typically from a
 * server response, or constructed directly in Javascript. The array is used
 * in place and becomes part of the constructed object. It is not cloned.
 * If no data is provided, the constructed object will be empty, but still
 * valid.
 * @extends {jspb.Message}
 * @constructor
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig = function(opt_data) {
  jspb.Message.initialize(this, opt_data, 0, -1, null, null);
};
goog.inherits(proto.nvidia.maxine.audio2face2d.v1.AnimateConfig, jspb.Message);
if (goog.DEBUG && !COMPILED) {
  /**
   * @public
   * @override
   */
  proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.displayName = 'proto.nvidia.maxine.audio2face2d.v1.AnimateConfig';
}
/**
 * Generated by JsPbCodeGenerator.
 * @param {Array=} opt_data Optional initial data array, typically from a
 * server response, or constructed directly in Javascript. The array is used
 * in place and becomes part of the constructed object. It is not cloned.
 * If no data is provided, the constructed object will be empty, but still
 * valid.
 * @extends {jspb.Message}
 * @constructor
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f = function(opt_data) {
  jspb.Message.initialize(this, opt_data, 0, -1, null, null);
};
goog.inherits(proto.nvidia.maxine.audio2face2d.v1.Vector3f, jspb.Message);
if (goog.DEBUG && !COMPILED) {
  /**
   * @public
   * @override
   */
  proto.nvidia.maxine.audio2face2d.v1.Vector3f.displayName = 'proto.nvidia.maxine.audio2face2d.v1.Vector3f';
}
/**
 * Generated by JsPbCodeGenerator.
 * @param {Array=} opt_data Optional initial data array, typically from a
 * server response, or constructed directly in Javascript. The array is used
 * in place and becomes part of the constructed object. It is not cloned.
 * If no data is provided, the constructed object will be empty, but still
 * valid.
 * @extends {jspb.Message}
 * @constructor
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream = function(opt_data) {
  jspb.Message.initialize(this, opt_data, 0, -1, proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.repeatedFields_, null);
};
goog.inherits(proto.nvidia.maxine.audio2face2d.v1.Vector3fStream, jspb.Message);
if (goog.DEBUG && !COMPILED) {
  /**
   * @public
   * @override
   */
  proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.displayName = 'proto.nvidia.maxine.audio2face2d.v1.Vector3fStream';
}
/**
 * Generated by JsPbCodeGenerator.
 * @param {Array=} opt_data Optional initial data array, typically from a
 * server response, or constructed directly in Javascript. The array is used
 * in place and becomes part of the constructed object. It is not cloned.
 * If no data is provided, the constructed object will be empty, but still
 * valid.
 * @extends {jspb.Message}
 * @constructor
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion = function(opt_data) {
  jspb.Message.initialize(this, opt_data, 0, -1, null, null);
};
goog.inherits(proto.nvidia.maxine.audio2face2d.v1.Quaternion, jspb.Message);
if (goog.DEBUG && !COMPILED) {
  /**
   * @public
   * @override
   */
  proto.nvidia.maxine.audio2face2d.v1.Quaternion.displayName = 'proto.nvidia.maxine.audio2face2d.v1.Quaternion';
}
/**
 * Generated by JsPbCodeGenerator.
 * @param {Array=} opt_data Optional initial data array, typically from a
 * server response, or constructed directly in Javascript. The array is used
 * in place and becomes part of the constructed object. It is not cloned.
 * If no data is provided, the constructed object will be empty, but still
 * valid.
 * @extends {jspb.Message}
 * @constructor
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream = function(opt_data) {
  jspb.Message.initialize(this, opt_data, 0, -1, proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.repeatedFields_, null);
};
goog.inherits(proto.nvidia.maxine.audio2face2d.v1.QuaternionStream, jspb.Message);
if (goog.DEBUG && !COMPILED) {
  /**
   * @public
   * @override
   */
  proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.displayName = 'proto.nvidia.maxine.audio2face2d.v1.QuaternionStream';
}
/**
 * Generated by JsPbCodeGenerator.
 * @param {Array=} opt_data Optional initial data array, typically from a
 * server response, or constructed directly in Javascript. The array is used
 * in place and becomes part of the constructed object. It is not cloned.
 * If no data is provided, the constructed object will be empty, but still
 * valid.
 * @extends {jspb.Message}
 * @constructor
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest = function(opt_data) {
  jspb.Message.initialize(this, opt_data, 0, -1, null, proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.oneofGroups_);
};
goog.inherits(proto.nvidia.maxine.audio2face2d.v1.AnimateRequest, jspb.Message);
if (goog.DEBUG && !COMPILED) {
  /**
   * @public
   * @override
   */
  proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.displayName = 'proto.nvidia.maxine.audio2face2d.v1.AnimateRequest';
}
/**
 * Generated by JsPbCodeGenerator.
 * @param {Array=} opt_data Optional initial data array, typically from a
 * server response, or constructed directly in Javascript. The array is used
 * in place and becomes part of the constructed object. It is not cloned.
 * If no data is provided, the constructed object will be empty, but still
 * valid.
 * @extends {jspb.Message}
 * @constructor
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse = function(opt_data) {
  jspb.Message.initialize(this, opt_data, 0, -1, null, proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.oneofGroups_);
};
goog.inherits(proto.nvidia.maxine.audio2face2d.v1.AnimateResponse, jspb.Message);
if (goog.DEBUG && !COMPILED) {
  /**
   * @public
   * @override
   */
  proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.displayName = 'proto.nvidia.maxine.audio2face2d.v1.AnimateResponse';
}



if (jspb.Message.GENERATE_TO_OBJECT) {
/**
 * Creates an object representation of this proto.
 * Field names that are reserved in JavaScript and will be renamed to pb_name.
 * Optional fields that are not set will be set to undefined.
 * To access a reserved field use, foo.pb_<name>, eg, foo.pb_default.
 * For the list of reserved names please see:
 *     net/proto2/compiler/js/internal/generator.cc#kKeyword.
 * @param {boolean=} opt_includeInstance Deprecated. whether to include the
 *     JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @return {!Object}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.toObject = function(opt_includeInstance) {
  return proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.toObject(opt_includeInstance, this);
};


/**
 * Static version of the {@see toObject} method.
 * @param {boolean|undefined} includeInstance Deprecated. Whether to include
 *     the JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @param {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} msg The msg instance to transform.
 * @return {!Object}
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.toObject = function(includeInstance, msg) {
  var f, obj = {
    portraitImage: msg.getPortraitImage_asB64(),
    modelSelection: jspb.Message.getFieldWithDefault(msg, 2, 0),
    animationCropMode: jspb.Message.getFieldWithDefault(msg, 3, 0),
    headPoseMode: jspb.Message.getFieldWithDefault(msg, 4, 0),
    enableLookaway: jspb.Message.getBooleanFieldWithDefault(msg, 5, false),
    lookawayMaxOffset: jspb.Message.getFieldWithDefault(msg, 6, 0),
    lookawayIntervalRange: jspb.Message.getFieldWithDefault(msg, 7, 0),
    lookawayIntervalMin: jspb.Message.getFieldWithDefault(msg, 8, 0),
    blinkFrequency: jspb.Message.getFieldWithDefault(msg, 9, 0),
    blinkDuration: jspb.Message.getFieldWithDefault(msg, 10, 0),
    mouthExpressionMultiplier: jspb.Message.getFloatingPointFieldWithDefault(msg, 11, 0.0),
    headPoseMultiplier: jspb.Message.getFloatingPointFieldWithDefault(msg, 12, 0.0),
    inputHeadRotation: (f = msg.getInputHeadRotation()) && proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.toObject(includeInstance, f),
    inputHeadTranslation: (f = msg.getInputHeadTranslation()) && proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.toObject(includeInstance, f)
  };

  if (includeInstance) {
    obj.$jspbMessageInstance = msg;
  }
  return obj;
};
}


/**
 * Deserializes binary data (in protobuf wire format).
 * @param {jspb.ByteSource} bytes The bytes to deserialize.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.deserializeBinary = function(bytes) {
  var reader = new jspb.BinaryReader(bytes);
  var msg = new proto.nvidia.maxine.audio2face2d.v1.AnimateConfig;
  return proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.deserializeBinaryFromReader(msg, reader);
};


/**
 * Deserializes binary data (in protobuf wire format) from the
 * given reader into the given message object.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} msg The message object to deserialize into.
 * @param {!jspb.BinaryReader} reader The BinaryReader to use.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.deserializeBinaryFromReader = function(msg, reader) {
  while (reader.nextField()) {
    if (reader.isEndGroup()) {
      break;
    }
    var field = reader.getFieldNumber();
    switch (field) {
    case 1:
      var value = /** @type {!Uint8Array} */ (reader.readBytes());
      msg.setPortraitImage(value);
      break;
    case 2:
      var value = /** @type {!proto.nvidia.maxine.audio2face2d.v1.ModelSelection} */ (reader.readEnum());
      msg.setModelSelection(value);
      break;
    case 3:
      var value = /** @type {!proto.nvidia.maxine.audio2face2d.v1.AnimationCroppingMode} */ (reader.readEnum());
      msg.setAnimationCropMode(value);
      break;
    case 4:
      var value = /** @type {!proto.nvidia.maxine.audio2face2d.v1.HeadPoseMode} */ (reader.readEnum());
      msg.setHeadPoseMode(value);
      break;
    case 5:
      var value = /** @type {boolean} */ (reader.readBool());
      msg.setEnableLookaway(value);
      break;
    case 6:
      var value = /** @type {number} */ (reader.readUint32());
      msg.setLookawayMaxOffset(value);
      break;
    case 7:
      var value = /** @type {number} */ (reader.readUint32());
      msg.setLookawayIntervalRange(value);
      break;
    case 8:
      var value = /** @type {number} */ (reader.readUint32());
      msg.setLookawayIntervalMin(value);
      break;
    case 9:
      var value = /** @type {number} */ (reader.readUint32());
      msg.setBlinkFrequency(value);
      break;
    case 10:
      var value = /** @type {number} */ (reader.readUint32());
      msg.setBlinkDuration(value);
      break;
    case 11:
      var value = /** @type {number} */ (reader.readFloat());
      msg.setMouthExpressionMultiplier(value);
      break;
    case 12:
      var value = /** @type {number} */ (reader.readFloat());
      msg.setHeadPoseMultiplier(value);
      break;
    case 13:
      var value = new proto.nvidia.maxine.audio2face2d.v1.QuaternionStream;
      reader.readMessage(value,proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.deserializeBinaryFromReader);
      msg.setInputHeadRotation(value);
      break;
    case 14:
      var value = new proto.nvidia.maxine.audio2face2d.v1.Vector3fStream;
      reader.readMessage(value,proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.deserializeBinaryFromReader);
      msg.setInputHeadTranslation(value);
      break;
    default:
      reader.skipField();
      break;
    }
  }
  return msg;
};


/**
 * Serializes the message to binary data (in protobuf wire format).
 * @return {!Uint8Array}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.serializeBinary = function() {
  var writer = new jspb.BinaryWriter();
  proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.serializeBinaryToWriter(this, writer);
  return writer.getResultBuffer();
};


/**
 * Serializes the given message to binary data (in protobuf wire
 * format), writing to the given BinaryWriter.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} message
 * @param {!jspb.BinaryWriter} writer
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.serializeBinaryToWriter = function(message, writer) {
  var f = undefined;
  f = message.getPortraitImage_asU8();
  if (f.length > 0) {
    writer.writeBytes(
      1,
      f
    );
  }
  f = /** @type {!proto.nvidia.maxine.audio2face2d.v1.ModelSelection} */ (jspb.Message.getField(message, 2));
  if (f != null) {
    writer.writeEnum(
      2,
      f
    );
  }
  f = /** @type {!proto.nvidia.maxine.audio2face2d.v1.AnimationCroppingMode} */ (jspb.Message.getField(message, 3));
  if (f != null) {
    writer.writeEnum(
      3,
      f
    );
  }
  f = /** @type {!proto.nvidia.maxine.audio2face2d.v1.HeadPoseMode} */ (jspb.Message.getField(message, 4));
  if (f != null) {
    writer.writeEnum(
      4,
      f
    );
  }
  f = /** @type {boolean} */ (jspb.Message.getField(message, 5));
  if (f != null) {
    writer.writeBool(
      5,
      f
    );
  }
  f = /** @type {number} */ (jspb.Message.getField(message, 6));
  if (f != null) {
    writer.writeUint32(
      6,
      f
    );
  }
  f = /** @type {number} */ (jspb.Message.getField(message, 7));
  if (f != null) {
    writer.writeUint32(
      7,
      f
    );
  }
  f = /** @type {number} */ (jspb.Message.getField(message, 8));
  if (f != null) {
    writer.writeUint32(
      8,
      f
    );
  }
  f = /** @type {number} */ (jspb.Message.getField(message, 9));
  if (f != null) {
    writer.writeUint32(
      9,
      f
    );
  }
  f = /** @type {number} */ (jspb.Message.getField(message, 10));
  if (f != null) {
    writer.writeUint32(
      10,
      f
    );
  }
  f = /** @type {number} */ (jspb.Message.getField(message, 11));
  if (f != null) {
    writer.writeFloat(
      11,
      f
    );
  }
  f = /** @type {number} */ (jspb.Message.getField(message, 12));
  if (f != null) {
    writer.writeFloat(
      12,
      f
    );
  }
  f = message.getInputHeadRotation();
  if (f != null) {
    writer.writeMessage(
      13,
      f,
      proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.serializeBinaryToWriter
    );
  }
  f = message.getInputHeadTranslation();
  if (f != null) {
    writer.writeMessage(
      14,
      f,
      proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.serializeBinaryToWriter
    );
  }
};


/**
 * optional bytes portrait_image = 1;
 * @return {!(string|Uint8Array)}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getPortraitImage = function() {
  return /** @type {!(string|Uint8Array)} */ (jspb.Message.getFieldWithDefault(this, 1, ""));
};


/**
 * optional bytes portrait_image = 1;
 * This is a type-conversion wrapper around `getPortraitImage()`
 * @return {string}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getPortraitImage_asB64 = function() {
  return /** @type {string} */ (jspb.Message.bytesAsB64(
      this.getPortraitImage()));
};


/**
 * optional bytes portrait_image = 1;
 * Note that Uint8Array is not supported on all browsers.
 * @see http://caniuse.com/Uint8Array
 * This is a type-conversion wrapper around `getPortraitImage()`
 * @return {!Uint8Array}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getPortraitImage_asU8 = function() {
  return /** @type {!Uint8Array} */ (jspb.Message.bytesAsU8(
      this.getPortraitImage()));
};


/**
 * @param {!(string|Uint8Array)} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setPortraitImage = function(value) {
  return jspb.Message.setProto3BytesField(this, 1, value);
};


/**
 * optional ModelSelection model_selection = 2;
 * @return {!proto.nvidia.maxine.audio2face2d.v1.ModelSelection}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getModelSelection = function() {
  return /** @type {!proto.nvidia.maxine.audio2face2d.v1.ModelSelection} */ (jspb.Message.getFieldWithDefault(this, 2, 0));
};


/**
 * @param {!proto.nvidia.maxine.audio2face2d.v1.ModelSelection} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setModelSelection = function(value) {
  return jspb.Message.setField(this, 2, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearModelSelection = function() {
  return jspb.Message.setField(this, 2, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasModelSelection = function() {
  return jspb.Message.getField(this, 2) != null;
};


/**
 * optional AnimationCroppingMode animation_crop_mode = 3;
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimationCroppingMode}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getAnimationCropMode = function() {
  return /** @type {!proto.nvidia.maxine.audio2face2d.v1.AnimationCroppingMode} */ (jspb.Message.getFieldWithDefault(this, 3, 0));
};


/**
 * @param {!proto.nvidia.maxine.audio2face2d.v1.AnimationCroppingMode} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setAnimationCropMode = function(value) {
  return jspb.Message.setField(this, 3, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearAnimationCropMode = function() {
  return jspb.Message.setField(this, 3, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasAnimationCropMode = function() {
  return jspb.Message.getField(this, 3) != null;
};


/**
 * optional HeadPoseMode head_pose_mode = 4;
 * @return {!proto.nvidia.maxine.audio2face2d.v1.HeadPoseMode}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getHeadPoseMode = function() {
  return /** @type {!proto.nvidia.maxine.audio2face2d.v1.HeadPoseMode} */ (jspb.Message.getFieldWithDefault(this, 4, 0));
};


/**
 * @param {!proto.nvidia.maxine.audio2face2d.v1.HeadPoseMode} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setHeadPoseMode = function(value) {
  return jspb.Message.setField(this, 4, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearHeadPoseMode = function() {
  return jspb.Message.setField(this, 4, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasHeadPoseMode = function() {
  return jspb.Message.getField(this, 4) != null;
};


/**
 * optional bool enable_lookaway = 5;
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getEnableLookaway = function() {
  return /** @type {boolean} */ (jspb.Message.getBooleanFieldWithDefault(this, 5, false));
};


/**
 * @param {boolean} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setEnableLookaway = function(value) {
  return jspb.Message.setField(this, 5, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearEnableLookaway = function() {
  return jspb.Message.setField(this, 5, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasEnableLookaway = function() {
  return jspb.Message.getField(this, 5) != null;
};


/**
 * optional uint32 lookaway_max_offset = 6;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getLookawayMaxOffset = function() {
  return /** @type {number} */ (jspb.Message.getFieldWithDefault(this, 6, 0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setLookawayMaxOffset = function(value) {
  return jspb.Message.setField(this, 6, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearLookawayMaxOffset = function() {
  return jspb.Message.setField(this, 6, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasLookawayMaxOffset = function() {
  return jspb.Message.getField(this, 6) != null;
};


/**
 * optional uint32 lookaway_interval_range = 7;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getLookawayIntervalRange = function() {
  return /** @type {number} */ (jspb.Message.getFieldWithDefault(this, 7, 0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setLookawayIntervalRange = function(value) {
  return jspb.Message.setField(this, 7, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearLookawayIntervalRange = function() {
  return jspb.Message.setField(this, 7, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasLookawayIntervalRange = function() {
  return jspb.Message.getField(this, 7) != null;
};


/**
 * optional uint32 lookaway_interval_min = 8;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getLookawayIntervalMin = function() {
  return /** @type {number} */ (jspb.Message.getFieldWithDefault(this, 8, 0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setLookawayIntervalMin = function(value) {
  return jspb.Message.setField(this, 8, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearLookawayIntervalMin = function() {
  return jspb.Message.setField(this, 8, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasLookawayIntervalMin = function() {
  return jspb.Message.getField(this, 8) != null;
};


/**
 * optional uint32 blink_frequency = 9;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getBlinkFrequency = function() {
  return /** @type {number} */ (jspb.Message.getFieldWithDefault(this, 9, 0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setBlinkFrequency = function(value) {
  return jspb.Message.setField(this, 9, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearBlinkFrequency = function() {
  return jspb.Message.setField(this, 9, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasBlinkFrequency = function() {
  return jspb.Message.getField(this, 9) != null;
};


/**
 * optional uint32 blink_duration = 10;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getBlinkDuration = function() {
  return /** @type {number} */ (jspb.Message.getFieldWithDefault(this, 10, 0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setBlinkDuration = function(value) {
  return jspb.Message.setField(this, 10, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearBlinkDuration = function() {
  return jspb.Message.setField(this, 10, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasBlinkDuration = function() {
  return jspb.Message.getField(this, 10) != null;
};


/**
 * optional float mouth_expression_multiplier = 11;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getMouthExpressionMultiplier = function() {
  return /** @type {number} */ (jspb.Message.getFloatingPointFieldWithDefault(this, 11, 0.0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setMouthExpressionMultiplier = function(value) {
  return jspb.Message.setField(this, 11, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearMouthExpressionMultiplier = function() {
  return jspb.Message.setField(this, 11, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasMouthExpressionMultiplier = function() {
  return jspb.Message.getField(this, 11) != null;
};


/**
 * optional float head_pose_multiplier = 12;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getHeadPoseMultiplier = function() {
  return /** @type {number} */ (jspb.Message.getFloatingPointFieldWithDefault(this, 12, 0.0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setHeadPoseMultiplier = function(value) {
  return jspb.Message.setField(this, 12, value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearHeadPoseMultiplier = function() {
  return jspb.Message.setField(this, 12, undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasHeadPoseMultiplier = function() {
  return jspb.Message.getField(this, 12) != null;
};


/**
 * optional QuaternionStream input_head_rotation = 13;
 * @return {?proto.nvidia.maxine.audio2face2d.v1.QuaternionStream}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getInputHeadRotation = function() {
  return /** @type{?proto.nvidia.maxine.audio2face2d.v1.QuaternionStream} */ (
    jspb.Message.getWrapperField(this, proto.nvidia.maxine.audio2face2d.v1.QuaternionStream, 13));
};


/**
 * @param {?proto.nvidia.maxine.audio2face2d.v1.QuaternionStream|undefined} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
*/
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setInputHeadRotation = function(value) {
  return jspb.Message.setWrapperField(this, 13, value);
};


/**
 * Clears the message field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearInputHeadRotation = function() {
  return this.setInputHeadRotation(undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasInputHeadRotation = function() {
  return jspb.Message.getField(this, 13) != null;
};


/**
 * optional Vector3fStream input_head_translation = 14;
 * @return {?proto.nvidia.maxine.audio2face2d.v1.Vector3fStream}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.getInputHeadTranslation = function() {
  return /** @type{?proto.nvidia.maxine.audio2face2d.v1.Vector3fStream} */ (
    jspb.Message.getWrapperField(this, proto.nvidia.maxine.audio2face2d.v1.Vector3fStream, 14));
};


/**
 * @param {?proto.nvidia.maxine.audio2face2d.v1.Vector3fStream|undefined} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
*/
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.setInputHeadTranslation = function(value) {
  return jspb.Message.setWrapperField(this, 14, value);
};


/**
 * Clears the message field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.clearInputHeadTranslation = function() {
  return this.setInputHeadTranslation(undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.prototype.hasInputHeadTranslation = function() {
  return jspb.Message.getField(this, 14) != null;
};





if (jspb.Message.GENERATE_TO_OBJECT) {
/**
 * Creates an object representation of this proto.
 * Field names that are reserved in JavaScript and will be renamed to pb_name.
 * Optional fields that are not set will be set to undefined.
 * To access a reserved field use, foo.pb_<name>, eg, foo.pb_default.
 * For the list of reserved names please see:
 *     net/proto2/compiler/js/internal/generator.cc#kKeyword.
 * @param {boolean=} opt_includeInstance Deprecated. whether to include the
 *     JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @return {!Object}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.prototype.toObject = function(opt_includeInstance) {
  return proto.nvidia.maxine.audio2face2d.v1.Vector3f.toObject(opt_includeInstance, this);
};


/**
 * Static version of the {@see toObject} method.
 * @param {boolean|undefined} includeInstance Deprecated. Whether to include
 *     the JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Vector3f} msg The msg instance to transform.
 * @return {!Object}
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.toObject = function(includeInstance, msg) {
  var f, obj = {
    x: jspb.Message.getFloatingPointFieldWithDefault(msg, 1, 0.0),
    y: jspb.Message.getFloatingPointFieldWithDefault(msg, 2, 0.0),
    z: jspb.Message.getFloatingPointFieldWithDefault(msg, 3, 0.0)
  };

  if (includeInstance) {
    obj.$jspbMessageInstance = msg;
  }
  return obj;
};
}


/**
 * Deserializes binary data (in protobuf wire format).
 * @param {jspb.ByteSource} bytes The bytes to deserialize.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Vector3f}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.deserializeBinary = function(bytes) {
  var reader = new jspb.BinaryReader(bytes);
  var msg = new proto.nvidia.maxine.audio2face2d.v1.Vector3f;
  return proto.nvidia.maxine.audio2face2d.v1.Vector3f.deserializeBinaryFromReader(msg, reader);
};


/**
 * Deserializes binary data (in protobuf wire format) from the
 * given reader into the given message object.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Vector3f} msg The message object to deserialize into.
 * @param {!jspb.BinaryReader} reader The BinaryReader to use.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Vector3f}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.deserializeBinaryFromReader = function(msg, reader) {
  while (reader.nextField()) {
    if (reader.isEndGroup()) {
      break;
    }
    var field = reader.getFieldNumber();
    switch (field) {
    case 1:
      var value = /** @type {number} */ (reader.readFloat());
      msg.setX(value);
      break;
    case 2:
      var value = /** @type {number} */ (reader.readFloat());
      msg.setY(value);
      break;
    case 3:
      var value = /** @type {number} */ (reader.readFloat());
      msg.setZ(value);
      break;
    default:
      reader.skipField();
      break;
    }
  }
  return msg;
};


/**
 * Serializes the message to binary data (in protobuf wire format).
 * @return {!Uint8Array}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.prototype.serializeBinary = function() {
  var writer = new jspb.BinaryWriter();
  proto.nvidia.maxine.audio2face2d.v1.Vector3f.serializeBinaryToWriter(this, writer);
  return writer.getResultBuffer();
};


/**
 * Serializes the given message to binary data (in protobuf wire
 * format), writing to the given BinaryWriter.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Vector3f} message
 * @param {!jspb.BinaryWriter} writer
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.serializeBinaryToWriter = function(message, writer) {
  var f = undefined;
  f = message.getX();
  if (f !== 0.0) {
    writer.writeFloat(
      1,
      f
    );
  }
  f = message.getY();
  if (f !== 0.0) {
    writer.writeFloat(
      2,
      f
    );
  }
  f = message.getZ();
  if (f !== 0.0) {
    writer.writeFloat(
      3,
      f
    );
  }
};


/**
 * optional float x = 1;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.prototype.getX = function() {
  return /** @type {number} */ (jspb.Message.getFloatingPointFieldWithDefault(this, 1, 0.0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Vector3f} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.prototype.setX = function(value) {
  return jspb.Message.setProto3FloatField(this, 1, value);
};


/**
 * optional float y = 2;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.prototype.getY = function() {
  return /** @type {number} */ (jspb.Message.getFloatingPointFieldWithDefault(this, 2, 0.0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Vector3f} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.prototype.setY = function(value) {
  return jspb.Message.setProto3FloatField(this, 2, value);
};


/**
 * optional float z = 3;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.prototype.getZ = function() {
  return /** @type {number} */ (jspb.Message.getFloatingPointFieldWithDefault(this, 3, 0.0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Vector3f} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3f.prototype.setZ = function(value) {
  return jspb.Message.setProto3FloatField(this, 3, value);
};



/**
 * List of repeated fields within this message type.
 * @private {!Array<number>}
 * @const
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.repeatedFields_ = [1];



if (jspb.Message.GENERATE_TO_OBJECT) {
/**
 * Creates an object representation of this proto.
 * Field names that are reserved in JavaScript and will be renamed to pb_name.
 * Optional fields that are not set will be set to undefined.
 * To access a reserved field use, foo.pb_<name>, eg, foo.pb_default.
 * For the list of reserved names please see:
 *     net/proto2/compiler/js/internal/generator.cc#kKeyword.
 * @param {boolean=} opt_includeInstance Deprecated. whether to include the
 *     JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @return {!Object}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.prototype.toObject = function(opt_includeInstance) {
  return proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.toObject(opt_includeInstance, this);
};


/**
 * Static version of the {@see toObject} method.
 * @param {boolean|undefined} includeInstance Deprecated. Whether to include
 *     the JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Vector3fStream} msg The msg instance to transform.
 * @return {!Object}
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.toObject = function(includeInstance, msg) {
  var f, obj = {
    valuesList: jspb.Message.toObjectList(msg.getValuesList(),
    proto.nvidia.maxine.audio2face2d.v1.Vector3f.toObject, includeInstance)
  };

  if (includeInstance) {
    obj.$jspbMessageInstance = msg;
  }
  return obj;
};
}


/**
 * Deserializes binary data (in protobuf wire format).
 * @param {jspb.ByteSource} bytes The bytes to deserialize.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Vector3fStream}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.deserializeBinary = function(bytes) {
  var reader = new jspb.BinaryReader(bytes);
  var msg = new proto.nvidia.maxine.audio2face2d.v1.Vector3fStream;
  return proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.deserializeBinaryFromReader(msg, reader);
};


/**
 * Deserializes binary data (in protobuf wire format) from the
 * given reader into the given message object.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Vector3fStream} msg The message object to deserialize into.
 * @param {!jspb.BinaryReader} reader The BinaryReader to use.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Vector3fStream}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.deserializeBinaryFromReader = function(msg, reader) {
  while (reader.nextField()) {
    if (reader.isEndGroup()) {
      break;
    }
    var field = reader.getFieldNumber();
    switch (field) {
    case 1:
      var value = new proto.nvidia.maxine.audio2face2d.v1.Vector3f;
      reader.readMessage(value,proto.nvidia.maxine.audio2face2d.v1.Vector3f.deserializeBinaryFromReader);
      msg.addValues(value);
      break;
    default:
      reader.skipField();
      break;
    }
  }
  return msg;
};


/**
 * Serializes the message to binary data (in protobuf wire format).
 * @return {!Uint8Array}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.prototype.serializeBinary = function() {
  var writer = new jspb.BinaryWriter();
  proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.serializeBinaryToWriter(this, writer);
  return writer.getResultBuffer();
};


/**
 * Serializes the given message to binary data (in protobuf wire
 * format), writing to the given BinaryWriter.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Vector3fStream} message
 * @param {!jspb.BinaryWriter} writer
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.serializeBinaryToWriter = function(message, writer) {
  var f = undefined;
  f = message.getValuesList();
  if (f.length > 0) {
    writer.writeRepeatedMessage(
      1,
      f,
      proto.nvidia.maxine.audio2face2d.v1.Vector3f.serializeBinaryToWriter
    );
  }
};


/**
 * repeated Vector3f values = 1;
 * @return {!Array<!proto.nvidia.maxine.audio2face2d.v1.Vector3f>}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.prototype.getValuesList = function() {
  return /** @type{!Array<!proto.nvidia.maxine.audio2face2d.v1.Vector3f>} */ (
    jspb.Message.getRepeatedWrapperField(this, proto.nvidia.maxine.audio2face2d.v1.Vector3f, 1));
};


/**
 * @param {!Array<!proto.nvidia.maxine.audio2face2d.v1.Vector3f>} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Vector3fStream} returns this
*/
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.prototype.setValuesList = function(value) {
  return jspb.Message.setRepeatedWrapperField(this, 1, value);
};


/**
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Vector3f=} opt_value
 * @param {number=} opt_index
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Vector3f}
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.prototype.addValues = function(opt_value, opt_index) {
  return jspb.Message.addToRepeatedWrapperField(this, 1, opt_value, proto.nvidia.maxine.audio2face2d.v1.Vector3f, opt_index);
};


/**
 * Clears the list making it empty but non-null.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Vector3fStream} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.Vector3fStream.prototype.clearValuesList = function() {
  return this.setValuesList([]);
};





if (jspb.Message.GENERATE_TO_OBJECT) {
/**
 * Creates an object representation of this proto.
 * Field names that are reserved in JavaScript and will be renamed to pb_name.
 * Optional fields that are not set will be set to undefined.
 * To access a reserved field use, foo.pb_<name>, eg, foo.pb_default.
 * For the list of reserved names please see:
 *     net/proto2/compiler/js/internal/generator.cc#kKeyword.
 * @param {boolean=} opt_includeInstance Deprecated. whether to include the
 *     JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @return {!Object}
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.prototype.toObject = function(opt_includeInstance) {
  return proto.nvidia.maxine.audio2face2d.v1.Quaternion.toObject(opt_includeInstance, this);
};


/**
 * Static version of the {@see toObject} method.
 * @param {boolean|undefined} includeInstance Deprecated. Whether to include
 *     the JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Quaternion} msg The msg instance to transform.
 * @return {!Object}
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.toObject = function(includeInstance, msg) {
  var f, obj = {
    x: jspb.Message.getFloatingPointFieldWithDefault(msg, 1, 0.0),
    y: jspb.Message.getFloatingPointFieldWithDefault(msg, 2, 0.0),
    z: jspb.Message.getFloatingPointFieldWithDefault(msg, 3, 0.0),
    w: jspb.Message.getFloatingPointFieldWithDefault(msg, 4, 0.0)
  };

  if (includeInstance) {
    obj.$jspbMessageInstance = msg;
  }
  return obj;
};
}


/**
 * Deserializes binary data (in protobuf wire format).
 * @param {jspb.ByteSource} bytes The bytes to deserialize.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Quaternion}
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.deserializeBinary = function(bytes) {
  var reader = new jspb.BinaryReader(bytes);
  var msg = new proto.nvidia.maxine.audio2face2d.v1.Quaternion;
  return proto.nvidia.maxine.audio2face2d.v1.Quaternion.deserializeBinaryFromReader(msg, reader);
};


/**
 * Deserializes binary data (in protobuf wire format) from the
 * given reader into the given message object.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Quaternion} msg The message object to deserialize into.
 * @param {!jspb.BinaryReader} reader The BinaryReader to use.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Quaternion}
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.deserializeBinaryFromReader = function(msg, reader) {
  while (reader.nextField()) {
    if (reader.isEndGroup()) {
      break;
    }
    var field = reader.getFieldNumber();
    switch (field) {
    case 1:
      var value = /** @type {number} */ (reader.readFloat());
      msg.setX(value);
      break;
    case 2:
      var value = /** @type {number} */ (reader.readFloat());
      msg.setY(value);
      break;
    case 3:
      var value = /** @type {number} */ (reader.readFloat());
      msg.setZ(value);
      break;
    case 4:
      var value = /** @type {number} */ (reader.readFloat());
      msg.setW(value);
      break;
    default:
      reader.skipField();
      break;
    }
  }
  return msg;
};


/**
 * Serializes the message to binary data (in protobuf wire format).
 * @return {!Uint8Array}
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.prototype.serializeBinary = function() {
  var writer = new jspb.BinaryWriter();
  proto.nvidia.maxine.audio2face2d.v1.Quaternion.serializeBinaryToWriter(this, writer);
  return writer.getResultBuffer();
};


/**
 * Serializes the given message to binary data (in protobuf wire
 * format), writing to the given BinaryWriter.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Quaternion} message
 * @param {!jspb.BinaryWriter} writer
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.serializeBinaryToWriter = function(message, writer) {
  var f = undefined;
  f = message.getX();
  if (f !== 0.0) {
    writer.writeFloat(
      1,
      f
    );
  }
  f = message.getY();
  if (f !== 0.0) {
    writer.writeFloat(
      2,
      f
    );
  }
  f = message.getZ();
  if (f !== 0.0) {
    writer.writeFloat(
      3,
      f
    );
  }
  f = message.getW();
  if (f !== 0.0) {
    writer.writeFloat(
      4,
      f
    );
  }
};


/**
 * optional float x = 1;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.prototype.getX = function() {
  return /** @type {number} */ (jspb.Message.getFloatingPointFieldWithDefault(this, 1, 0.0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Quaternion} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.prototype.setX = function(value) {
  return jspb.Message.setProto3FloatField(this, 1, value);
};


/**
 * optional float y = 2;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.prototype.getY = function() {
  return /** @type {number} */ (jspb.Message.getFloatingPointFieldWithDefault(this, 2, 0.0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Quaternion} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.prototype.setY = function(value) {
  return jspb.Message.setProto3FloatField(this, 2, value);
};


/**
 * optional float z = 3;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.prototype.getZ = function() {
  return /** @type {number} */ (jspb.Message.getFloatingPointFieldWithDefault(this, 3, 0.0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Quaternion} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.prototype.setZ = function(value) {
  return jspb.Message.setProto3FloatField(this, 3, value);
};


/**
 * optional float w = 4;
 * @return {number}
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.prototype.getW = function() {
  return /** @type {number} */ (jspb.Message.getFloatingPointFieldWithDefault(this, 4, 0.0));
};


/**
 * @param {number} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Quaternion} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.Quaternion.prototype.setW = function(value) {
  return jspb.Message.setProto3FloatField(this, 4, value);
};



/**
 * List of repeated fields within this message type.
 * @private {!Array<number>}
 * @const
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.repeatedFields_ = [1];



if (jspb.Message.GENERATE_TO_OBJECT) {
/**
 * Creates an object representation of this proto.
 * Field names that are reserved in JavaScript and will be renamed to pb_name.
 * Optional fields that are not set will be set to undefined.
 * To access a reserved field use, foo.pb_<name>, eg, foo.pb_default.
 * For the list of reserved names please see:
 *     net/proto2/compiler/js/internal/generator.cc#kKeyword.
 * @param {boolean=} opt_includeInstance Deprecated. whether to include the
 *     JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @return {!Object}
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.prototype.toObject = function(opt_includeInstance) {
  return proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.toObject(opt_includeInstance, this);
};


/**
 * Static version of the {@see toObject} method.
 * @param {boolean|undefined} includeInstance Deprecated. Whether to include
 *     the JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @param {!proto.nvidia.maxine.audio2face2d.v1.QuaternionStream} msg The msg instance to transform.
 * @return {!Object}
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.toObject = function(includeInstance, msg) {
  var f, obj = {
    valuesList: jspb.Message.toObjectList(msg.getValuesList(),
    proto.nvidia.maxine.audio2face2d.v1.Quaternion.toObject, includeInstance)
  };

  if (includeInstance) {
    obj.$jspbMessageInstance = msg;
  }
  return obj;
};
}


/**
 * Deserializes binary data (in protobuf wire format).
 * @param {jspb.ByteSource} bytes The bytes to deserialize.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.QuaternionStream}
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.deserializeBinary = function(bytes) {
  var reader = new jspb.BinaryReader(bytes);
  var msg = new proto.nvidia.maxine.audio2face2d.v1.QuaternionStream;
  return proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.deserializeBinaryFromReader(msg, reader);
};


/**
 * Deserializes binary data (in protobuf wire format) from the
 * given reader into the given message object.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.QuaternionStream} msg The message object to deserialize into.
 * @param {!jspb.BinaryReader} reader The BinaryReader to use.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.QuaternionStream}
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.deserializeBinaryFromReader = function(msg, reader) {
  while (reader.nextField()) {
    if (reader.isEndGroup()) {
      break;
    }
    var field = reader.getFieldNumber();
    switch (field) {
    case 1:
      var value = new proto.nvidia.maxine.audio2face2d.v1.Quaternion;
      reader.readMessage(value,proto.nvidia.maxine.audio2face2d.v1.Quaternion.deserializeBinaryFromReader);
      msg.addValues(value);
      break;
    default:
      reader.skipField();
      break;
    }
  }
  return msg;
};


/**
 * Serializes the message to binary data (in protobuf wire format).
 * @return {!Uint8Array}
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.prototype.serializeBinary = function() {
  var writer = new jspb.BinaryWriter();
  proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.serializeBinaryToWriter(this, writer);
  return writer.getResultBuffer();
};


/**
 * Serializes the given message to binary data (in protobuf wire
 * format), writing to the given BinaryWriter.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.QuaternionStream} message
 * @param {!jspb.BinaryWriter} writer
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.serializeBinaryToWriter = function(message, writer) {
  var f = undefined;
  f = message.getValuesList();
  if (f.length > 0) {
    writer.writeRepeatedMessage(
      1,
      f,
      proto.nvidia.maxine.audio2face2d.v1.Quaternion.serializeBinaryToWriter
    );
  }
};


/**
 * repeated Quaternion values = 1;
 * @return {!Array<!proto.nvidia.maxine.audio2face2d.v1.Quaternion>}
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.prototype.getValuesList = function() {
  return /** @type{!Array<!proto.nvidia.maxine.audio2face2d.v1.Quaternion>} */ (
    jspb.Message.getRepeatedWrapperField(this, proto.nvidia.maxine.audio2face2d.v1.Quaternion, 1));
};


/**
 * @param {!Array<!proto.nvidia.maxine.audio2face2d.v1.Quaternion>} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.QuaternionStream} returns this
*/
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.prototype.setValuesList = function(value) {
  return jspb.Message.setRepeatedWrapperField(this, 1, value);
};


/**
 * @param {!proto.nvidia.maxine.audio2face2d.v1.Quaternion=} opt_value
 * @param {number=} opt_index
 * @return {!proto.nvidia.maxine.audio2face2d.v1.Quaternion}
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.prototype.addValues = function(opt_value, opt_index) {
  return jspb.Message.addToRepeatedWrapperField(this, 1, opt_value, proto.nvidia.maxine.audio2face2d.v1.Quaternion, opt_index);
};


/**
 * Clears the list making it empty but non-null.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.QuaternionStream} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.QuaternionStream.prototype.clearValuesList = function() {
  return this.setValuesList([]);
};



/**
 * Oneof group definitions for this message. Each group defines the field
 * numbers belonging to that group. When of these fields' value is set, all
 * other fields in the group are cleared. During deserialization, if multiple
 * fields are encountered for a group, only the last value seen will be kept.
 * @private {!Array<!Array<number>>}
 * @const
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.oneofGroups_ = [[1,2]];

/**
 * @enum {number}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.StreamInputCase = {
  STREAM_INPUT_NOT_SET: 0,
  CONFIG: 1,
  AUDIO_FILE_DATA: 2
};

/**
 * @return {proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.StreamInputCase}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.getStreamInputCase = function() {
  return /** @type {proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.StreamInputCase} */(jspb.Message.computeOneofCase(this, proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.oneofGroups_[0]));
};



if (jspb.Message.GENERATE_TO_OBJECT) {
/**
 * Creates an object representation of this proto.
 * Field names that are reserved in JavaScript and will be renamed to pb_name.
 * Optional fields that are not set will be set to undefined.
 * To access a reserved field use, foo.pb_<name>, eg, foo.pb_default.
 * For the list of reserved names please see:
 *     net/proto2/compiler/js/internal/generator.cc#kKeyword.
 * @param {boolean=} opt_includeInstance Deprecated. whether to include the
 *     JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @return {!Object}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.toObject = function(opt_includeInstance) {
  return proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.toObject(opt_includeInstance, this);
};


/**
 * Static version of the {@see toObject} method.
 * @param {boolean|undefined} includeInstance Deprecated. Whether to include
 *     the JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @param {!proto.nvidia.maxine.audio2face2d.v1.AnimateRequest} msg The msg instance to transform.
 * @return {!Object}
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.toObject = function(includeInstance, msg) {
  var f, obj = {
    config: (f = msg.getConfig()) && proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.toObject(includeInstance, f),
    audioFileData: msg.getAudioFileData_asB64()
  };

  if (includeInstance) {
    obj.$jspbMessageInstance = msg;
  }
  return obj;
};
}


/**
 * Deserializes binary data (in protobuf wire format).
 * @param {jspb.ByteSource} bytes The bytes to deserialize.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateRequest}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.deserializeBinary = function(bytes) {
  var reader = new jspb.BinaryReader(bytes);
  var msg = new proto.nvidia.maxine.audio2face2d.v1.AnimateRequest;
  return proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.deserializeBinaryFromReader(msg, reader);
};


/**
 * Deserializes binary data (in protobuf wire format) from the
 * given reader into the given message object.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.AnimateRequest} msg The message object to deserialize into.
 * @param {!jspb.BinaryReader} reader The BinaryReader to use.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateRequest}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.deserializeBinaryFromReader = function(msg, reader) {
  while (reader.nextField()) {
    if (reader.isEndGroup()) {
      break;
    }
    var field = reader.getFieldNumber();
    switch (field) {
    case 1:
      var value = new proto.nvidia.maxine.audio2face2d.v1.AnimateConfig;
      reader.readMessage(value,proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.deserializeBinaryFromReader);
      msg.setConfig(value);
      break;
    case 2:
      var value = /** @type {!Uint8Array} */ (reader.readBytes());
      msg.setAudioFileData(value);
      break;
    default:
      reader.skipField();
      break;
    }
  }
  return msg;
};


/**
 * Serializes the message to binary data (in protobuf wire format).
 * @return {!Uint8Array}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.serializeBinary = function() {
  var writer = new jspb.BinaryWriter();
  proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.serializeBinaryToWriter(this, writer);
  return writer.getResultBuffer();
};


/**
 * Serializes the given message to binary data (in protobuf wire
 * format), writing to the given BinaryWriter.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.AnimateRequest} message
 * @param {!jspb.BinaryWriter} writer
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.serializeBinaryToWriter = function(message, writer) {
  var f = undefined;
  f = message.getConfig();
  if (f != null) {
    writer.writeMessage(
      1,
      f,
      proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.serializeBinaryToWriter
    );
  }
  f = /** @type {!(string|Uint8Array)} */ (jspb.Message.getField(message, 2));
  if (f != null) {
    writer.writeBytes(
      2,
      f
    );
  }
};


/**
 * optional AnimateConfig config = 1;
 * @return {?proto.nvidia.maxine.audio2face2d.v1.AnimateConfig}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.getConfig = function() {
  return /** @type{?proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} */ (
    jspb.Message.getWrapperField(this, proto.nvidia.maxine.audio2face2d.v1.AnimateConfig, 1));
};


/**
 * @param {?proto.nvidia.maxine.audio2face2d.v1.AnimateConfig|undefined} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateRequest} returns this
*/
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.setConfig = function(value) {
  return jspb.Message.setOneofWrapperField(this, 1, proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.oneofGroups_[0], value);
};


/**
 * Clears the message field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateRequest} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.clearConfig = function() {
  return this.setConfig(undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.hasConfig = function() {
  return jspb.Message.getField(this, 1) != null;
};


/**
 * optional bytes audio_file_data = 2;
 * @return {!(string|Uint8Array)}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.getAudioFileData = function() {
  return /** @type {!(string|Uint8Array)} */ (jspb.Message.getFieldWithDefault(this, 2, ""));
};


/**
 * optional bytes audio_file_data = 2;
 * This is a type-conversion wrapper around `getAudioFileData()`
 * @return {string}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.getAudioFileData_asB64 = function() {
  return /** @type {string} */ (jspb.Message.bytesAsB64(
      this.getAudioFileData()));
};


/**
 * optional bytes audio_file_data = 2;
 * Note that Uint8Array is not supported on all browsers.
 * @see http://caniuse.com/Uint8Array
 * This is a type-conversion wrapper around `getAudioFileData()`
 * @return {!Uint8Array}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.getAudioFileData_asU8 = function() {
  return /** @type {!Uint8Array} */ (jspb.Message.bytesAsU8(
      this.getAudioFileData()));
};


/**
 * @param {!(string|Uint8Array)} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateRequest} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.setAudioFileData = function(value) {
  return jspb.Message.setOneofField(this, 2, proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.oneofGroups_[0], value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateRequest} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.clearAudioFileData = function() {
  return jspb.Message.setOneofField(this, 2, proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.oneofGroups_[0], undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateRequest.prototype.hasAudioFileData = function() {
  return jspb.Message.getField(this, 2) != null;
};



/**
 * Oneof group definitions for this message. Each group defines the field
 * numbers belonging to that group. When of these fields' value is set, all
 * other fields in the group are cleared. During deserialization, if multiple
 * fields are encountered for a group, only the last value seen will be kept.
 * @private {!Array<!Array<number>>}
 * @const
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.oneofGroups_ = [[1,2,3]];

/**
 * @enum {number}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.StreamOutputCase = {
  STREAM_OUTPUT_NOT_SET: 0,
  CONFIG: 1,
  VIDEO_FILE_DATA: 2,
  KEEP_ALIVE: 3
};

/**
 * @return {proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.StreamOutputCase}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.getStreamOutputCase = function() {
  return /** @type {proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.StreamOutputCase} */(jspb.Message.computeOneofCase(this, proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.oneofGroups_[0]));
};



if (jspb.Message.GENERATE_TO_OBJECT) {
/**
 * Creates an object representation of this proto.
 * Field names that are reserved in JavaScript and will be renamed to pb_name.
 * Optional fields that are not set will be set to undefined.
 * To access a reserved field use, foo.pb_<name>, eg, foo.pb_default.
 * For the list of reserved names please see:
 *     net/proto2/compiler/js/internal/generator.cc#kKeyword.
 * @param {boolean=} opt_includeInstance Deprecated. whether to include the
 *     JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @return {!Object}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.toObject = function(opt_includeInstance) {
  return proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.toObject(opt_includeInstance, this);
};


/**
 * Static version of the {@see toObject} method.
 * @param {boolean|undefined} includeInstance Deprecated. Whether to include
 *     the JSPB instance for transitional soy proto support:
 *     http://goto/soy-param-migration
 * @param {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse} msg The msg instance to transform.
 * @return {!Object}
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.toObject = function(includeInstance, msg) {
  var f, obj = {
    config: (f = msg.getConfig()) && proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.toObject(includeInstance, f),
    videoFileData: msg.getVideoFileData_asB64(),
    keepAlive: (f = msg.getKeepAlive()) && google_protobuf_empty_pb.Empty.toObject(includeInstance, f)
  };

  if (includeInstance) {
    obj.$jspbMessageInstance = msg;
  }
  return obj;
};
}


/**
 * Deserializes binary data (in protobuf wire format).
 * @param {jspb.ByteSource} bytes The bytes to deserialize.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.deserializeBinary = function(bytes) {
  var reader = new jspb.BinaryReader(bytes);
  var msg = new proto.nvidia.maxine.audio2face2d.v1.AnimateResponse;
  return proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.deserializeBinaryFromReader(msg, reader);
};


/**
 * Deserializes binary data (in protobuf wire format) from the
 * given reader into the given message object.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse} msg The message object to deserialize into.
 * @param {!jspb.BinaryReader} reader The BinaryReader to use.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.deserializeBinaryFromReader = function(msg, reader) {
  while (reader.nextField()) {
    if (reader.isEndGroup()) {
      break;
    }
    var field = reader.getFieldNumber();
    switch (field) {
    case 1:
      var value = new proto.nvidia.maxine.audio2face2d.v1.AnimateConfig;
      reader.readMessage(value,proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.deserializeBinaryFromReader);
      msg.setConfig(value);
      break;
    case 2:
      var value = /** @type {!Uint8Array} */ (reader.readBytes());
      msg.setVideoFileData(value);
      break;
    case 3:
      var value = new google_protobuf_empty_pb.Empty;
      reader.readMessage(value,google_protobuf_empty_pb.Empty.deserializeBinaryFromReader);
      msg.setKeepAlive(value);
      break;
    default:
      reader.skipField();
      break;
    }
  }
  return msg;
};


/**
 * Serializes the message to binary data (in protobuf wire format).
 * @return {!Uint8Array}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.serializeBinary = function() {
  var writer = new jspb.BinaryWriter();
  proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.serializeBinaryToWriter(this, writer);
  return writer.getResultBuffer();
};


/**
 * Serializes the given message to binary data (in protobuf wire
 * format), writing to the given BinaryWriter.
 * @param {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse} message
 * @param {!jspb.BinaryWriter} writer
 * @suppress {unusedLocalVariables} f is only used for nested messages
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.serializeBinaryToWriter = function(message, writer) {
  var f = undefined;
  f = message.getConfig();
  if (f != null) {
    writer.writeMessage(
      1,
      f,
      proto.nvidia.maxine.audio2face2d.v1.AnimateConfig.serializeBinaryToWriter
    );
  }
  f = /** @type {!(string|Uint8Array)} */ (jspb.Message.getField(message, 2));
  if (f != null) {
    writer.writeBytes(
      2,
      f
    );
  }
  f = message.getKeepAlive();
  if (f != null) {
    writer.writeMessage(
      3,
      f,
      google_protobuf_empty_pb.Empty.serializeBinaryToWriter
    );
  }
};


/**
 * optional AnimateConfig config = 1;
 * @return {?proto.nvidia.maxine.audio2face2d.v1.AnimateConfig}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.getConfig = function() {
  return /** @type{?proto.nvidia.maxine.audio2face2d.v1.AnimateConfig} */ (
    jspb.Message.getWrapperField(this, proto.nvidia.maxine.audio2face2d.v1.AnimateConfig, 1));
};


/**
 * @param {?proto.nvidia.maxine.audio2face2d.v1.AnimateConfig|undefined} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse} returns this
*/
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.setConfig = function(value) {
  return jspb.Message.setOneofWrapperField(this, 1, proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.oneofGroups_[0], value);
};


/**
 * Clears the message field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.clearConfig = function() {
  return this.setConfig(undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.hasConfig = function() {
  return jspb.Message.getField(this, 1) != null;
};


/**
 * optional bytes video_file_data = 2;
 * @return {!(string|Uint8Array)}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.getVideoFileData = function() {
  return /** @type {!(string|Uint8Array)} */ (jspb.Message.getFieldWithDefault(this, 2, ""));
};


/**
 * optional bytes video_file_data = 2;
 * This is a type-conversion wrapper around `getVideoFileData()`
 * @return {string}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.getVideoFileData_asB64 = function() {
  return /** @type {string} */ (jspb.Message.bytesAsB64(
      this.getVideoFileData()));
};


/**
 * optional bytes video_file_data = 2;
 * Note that Uint8Array is not supported on all browsers.
 * @see http://caniuse.com/Uint8Array
 * This is a type-conversion wrapper around `getVideoFileData()`
 * @return {!Uint8Array}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.getVideoFileData_asU8 = function() {
  return /** @type {!Uint8Array} */ (jspb.Message.bytesAsU8(
      this.getVideoFileData()));
};


/**
 * @param {!(string|Uint8Array)} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.setVideoFileData = function(value) {
  return jspb.Message.setOneofField(this, 2, proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.oneofGroups_[0], value);
};


/**
 * Clears the field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.clearVideoFileData = function() {
  return jspb.Message.setOneofField(this, 2, proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.oneofGroups_[0], undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.hasVideoFileData = function() {
  return jspb.Message.getField(this, 2) != null;
};


/**
 * optional google.protobuf.Empty keep_alive = 3;
 * @return {?proto.google.protobuf.Empty}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.getKeepAlive = function() {
  return /** @type{?proto.google.protobuf.Empty} */ (
    jspb.Message.getWrapperField(this, google_protobuf_empty_pb.Empty, 3));
};


/**
 * @param {?proto.google.protobuf.Empty|undefined} value
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse} returns this
*/
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.setKeepAlive = function(value) {
  return jspb.Message.setOneofWrapperField(this, 3, proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.oneofGroups_[0], value);
};


/**
 * Clears the message field making it undefined.
 * @return {!proto.nvidia.maxine.audio2face2d.v1.AnimateResponse} returns this
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.clearKeepAlive = function() {
  return this.setKeepAlive(undefined);
};


/**
 * Returns whether this field is set.
 * @return {boolean}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimateResponse.prototype.hasKeepAlive = function() {
  return jspb.Message.getField(this, 3) != null;
};


/**
 * @enum {number}
 */
proto.nvidia.maxine.audio2face2d.v1.ModelSelection = {
  MODEL_SELECTION_UNSPECIFIED: 0,
  MODEL_SELECTION_PERF: 1,
  MODEL_SELECTION_QUALITY: 2
};

/**
 * @enum {number}
 */
proto.nvidia.maxine.audio2face2d.v1.AnimationCroppingMode = {
  ANIMATION_CROPPING_MODE_UNSPECIFIED: 0,
  ANIMATION_CROPPING_MODE_FACEBOX: 1,
  ANIMATION_CROPPING_MODE_REGISTRATION_BLENDING: 2,
  ANIMATION_CROPPING_MODE_INSET_BLENDING: 3
};

/**
 * @enum {number}
 */
proto.nvidia.maxine.audio2face2d.v1.HeadPoseMode = {
  HEAD_POSE_MODE_UNSPECIFIED: 0,
  HEAD_POSE_MODE_RETAIN_FROM_PORTRAIT_IMAGE: 1,
  HEAD_POSE_MODE_PRE_DEFINED_ANIMATION: 2,
  HEAD_POSE_MODE_USER_DEFINED_ANIMATION: 3
};

goog.object.extend(exports, proto.nvidia.maxine.audio2face2d.v1);
